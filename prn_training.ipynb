{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"prn_training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8Tic1rpj4wwR"},"source":["# Library"]},{"cell_type":"code","metadata":{"id":"XXduJnaub7Rr"},"source":["import os, os.path\n","\n","import torch\n","tr = torch\n","import torch.nn as nn\n","from torch.nn import init\n","import torchvision as tv\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.nn.utils.spectral_norm as spectral_norm\n","\n","import re\n","import numpy as np\n","import cv2\n","import random\n","from PIL import Image \n","\n","from scipy.io import loadmat\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","from numpy import linalg as LA\n","\n","from torch.utils.data import DataLoader\n","import json\n","import h5py\n","\n","from torchvision.transforms import RandomRotation, ToPILImage, ToTensor, ColorJitter\n","import torchvision.transforms.functional as TF\n","from sklearn.model_selection import train_test_split\n","\n","\n","import sys\n","import argparse\n","from tqdm import tqdm\n","from types import SimpleNamespace\n","import glob\n","\n","# Fix random seed for reproducability\n","rseed = 43\n","np.random.seed(rseed)\n","torch.backends.cudnn.deterministic = True\n","torch.manual_seed(rseed)\n","if torch.cuda.is_available():\n","  torch.cuda.manual_seed_all(rseed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wDlJGx0U5U7e"},"source":["# Dataloader"]},{"cell_type":"code","metadata":{"id":"Nh3fkInvgr_n"},"source":["import pandas as pd\n","class DatasetUBFC(Dataset):\n","  \"\"\"\n","      Dataset class for training network.\n","  \"\"\"\n","  def __init__(\n","      self, root_dir, session_names, num_samples, \n","      seq_length, resize_shape, val=False, transform=False):\n","    \"\"\"\n","    :param path: Path to hdf5 file\n","    :param labels: tuple of label names to use (e.g.: ('pulseNumerical', 'resp_signal') or ('pulse_signal', ) )\n","        Note that the first label must be the pulse rate if it is present!\n","    \"\"\"\n","\n","    # self.hr_path = hr_path\n","    self.resize_shape = resize_shape\n","    self.transform = transform\n","    self.sessions = session_names\n","    self.seq_length = seq_length    \n","\n","    self.all_sessions = []\n","    self.length = num_samples\n","    self.ppg_der = {}\n","    self.frames = {}\n","    self.avg_img = {}\n","    self.hr = {}\n","    \n","    print(len(self.sessions),self.sessions) \n","    self.files = os.listdir(root_dir[1])\n","    print(len(self.files))\n","    i = -1\n","   \n","    len_session = 1\n","    for num_dataset in range(len_session):\n","      print(num_dataset)\n","      print(len(self.sessions[num_dataset]))\n","      for session_num, session in enumerate(self.sessions[num_dataset]):\n","        i += 1\n","        if num_dataset == 0:\n","       \n","          db = h5py.File(os.path.join(root_dir[num_dataset], session + '.h5'), 'r')\n","        else:\n","          # print(self.files[session])\n","          db = h5py.File(os.path.join(root_dir[num_dataset], self.files[session]), 'r')\n","\n","        frames = db['dataset_1']\n","        target = db['ppg']\n","\n","        # Normalize PPG\n","        target = target - np.mean(target)\n","        target = target / np.std(target) #target = target / np.max(np.abs(target))\n","\n","        self.frames[i] = frames\n","        self.ppg_der[i] = target\n","        # self.avg_img[session] = avg_img\n","    print('frames.shape', len(self.frames))\n","    \n","  def __len__(self):\n","    return (self.length)\n","\n","  def __getitem__(self, idx):\n","\n","    # Pick a session\n","    session_num = np.random.randint(low=0, high=len(self.frames))\n","\n","    frames = self.frames[session_num]\n","    cur_ppg_signal = self.ppg_der[session_num]\n","    # avg_img = self.avg_img[subject].clone()\n","    \n","    # Pick a random frame\n","    cur_frame_num = np.random.randint(\n","        low=0, high=len(frames) - self.seq_length # Can't pick the last frame.\n","        )\n","\n","    # Flip\n","    if self.transform:\n","      k = random.randint(0, 1)\n","      k_h = random.randint(0, 1)\n","\n","    # Following frames\n","    temp_next_frames_list = []\n","    temp_next_ppgs_list = []\n","    \n","    for j in range(self.seq_length):\n","      next_frame = frames[cur_frame_num + j]\n","      next_frame = cv2.resize(\n","          next_frame, self.resize_shape, \n","          interpolation=cv2.INTER_LINEAR\n","          )\n","      next_frame = torch.from_numpy(next_frame).permute(2, 0, 1).float()\n","      next_frame = next_frame / 127.5 - 1\n","      \n","      # Augmentation\n","      if (self.transform == True) and (k == 1):\n","        next_frame = torch.flip(next_frame, [2])\n","      if (self.transform == True) and (k_h == 1):\n","        next_frame = torch.flip(next_frame, [1])\n","\n","      # PPG\n","      next_ppg_value = cur_ppg_signal[cur_frame_num + j]\n","\n","      temp_next_frames_list.append(next_frame)\n","      temp_next_ppgs_list.append(\n","          torch.tensor(next_ppg_value).float()\n","          )\n","    \n","    # Return\n","    data = {\n","      'next_frame': torch.stack(temp_next_frames_list),\n","      # 'hr': np.mean(hr),\n","      'next_ppg_value': torch.stack(temp_next_ppgs_list),\n","    }\n","\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DK09-Xdh5YLL"},"source":["# Loss"]},{"cell_type":"code","metadata":{"id":"OZjpp9ZudRw_"},"source":["class Neg_Pearson(nn.Module):    # Pearson range [-1, 1] so if < 0, abs|loss| ; if >0, 1- loss\n","  def __init__(self):\n","    super(Neg_Pearson,self).__init__()\n","    return\n","      \n","  def forward(self, preds, labels):       # all variable operation\n","    loss = torch.tensor(0).float().to(preds.device)\n","    # preds = (preds - torch.mean(preds)) / torch.std(preds)\n","    # labels = (labels - torch.mean(labels)) / torch.std(labels)\n","    for i in range(preds.shape[0]):\n","      preds_nor = (preds[i] - torch.mean(preds[i])) / (torch.std(preds[i]))\n","      labels_nor = (labels[i] - torch.mean(labels[i])) / (torch.std(labels[i]))\n","\n","      if torch.sum(torch.isnan(preds_nor)) or torch.sum(torch.isnan(labels_nor)):\n","          continue\n","\n","      #sum_x = torch.sum((preds[i] - torch.mean(preds[i])) / torch.std(preds[i]))               # x\n","      #sum_y = torch.sum((labels[i] - torch.mean(labels[i])) / torch.std(labels[i]))               # y\n","      sum_x = torch.sum(preds_nor)                # x\n","      sum_y = torch.sum(labels_nor)               # y\n","      sum_xy = torch.sum(preds_nor * labels_nor)        # xy\n","      sum_x2 = torch.sum(torch.pow(preds_nor, 2))  # x^2\n","      sum_y2 = torch.sum(torch.pow(labels_nor, 2)) # y^2\n","      N = preds.shape[1]\n","      pearson = (N*sum_xy - sum_x*sum_y)/(torch.sqrt((N*sum_x2 - torch.pow(sum_x,2))*(N*sum_y2 - torch.pow(sum_y,2)))+1e-7)\n","      # print(pearson, sum_xy, sum_x2, sum_y2)\n","      # print(labels[i])\n","\n","\n","      # if (pearson>=0).data.cpu().numpy():    # torch.cuda.ByteTensor -->  numpy\n","      #    loss += 1 - pearson\n","      # else:\n","      #    loss += 1 - torch.abs(pearson)\n","      \n","      loss += 1 - pearson\n","        \n","    loss = loss/preds.shape[0]\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZtqNC595bdC"},"source":["# Network"]},{"cell_type":"code","metadata":{"id":"VhQaWp0TkQqh"},"source":["class RPPGNetResnet(nn.Module):\n","  def __init__(self, seq_length):\n","    super().__init__()\n","\n","    self.learned_shortcut1 = nn.Conv3d(3, 16, kernel_size=1, bias=False)\n","    self.layers1 = nn.Sequential(\n","        nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(16),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0),\n","        nn.Conv3d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(16),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)\n","    )\n","    self.pool1 = nn.AvgPool3d(kernel_size=(1, 4, 4), stride=(1, 4, 4), padding=0)\n","\n","    self.learned_shortcut2 = nn.Conv3d(16, 64, kernel_size=1, bias=False)\n","    self.layers2 = nn.Sequential(\n","        nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(32),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0),\n","        nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(64),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)\n","    )\n","    self.pool2 = nn.AvgPool3d(kernel_size=(1, 4, 4), stride=(1, 4, 4), padding=0)\n","\n","    self.learned_shortcut3 = nn.Conv3d(64, 256, kernel_size=1, bias=False)\n","    self.layers3 = nn.Sequential(\n","        nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(128),\n","        nn.ReLU(),\n","        nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 1, 1)),\n","        nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm3d(256),\n","        nn.ReLU()\n","    )\n","    \n","    self.pool3 = nn.AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 1, 1))\n","\n","    self.pooling = nn.AdaptiveAvgPool3d((seq_length, 1, 1))\n","    self.final_conv = nn.Conv3d(in_channels=256, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n","    \n","  def forward(self, A):   \n","\n","    identity = A\n","    out = self.layers1(A)   \n","    out += self.learned_shortcut1(self.pool1(identity))\n","  \n","    identity = out \n","    out = self.layers2(out)\n","    out += self.learned_shortcut2(self.pool2(identity))\n","    \n","    identity = out\n","    out = self.layers3(out)\n","    out += self.learned_shortcut3(self.pool3(identity))\n","\n","    out = self.pooling(out)\n","    out = self.final_conv(out)\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4fSnWtMf5ekD"},"source":["# Train function"]},{"cell_type":"code","metadata":{"id":"l0tTZUQcb_-X"},"source":["def train_model(model, dataloaders, criterion, optimizer, scheduler, params):\n","  val_loss_history = []\n","  train_loss_history = []\n","\n","  criterion_SNR = SNRLoss()\n","\n","  min_train_loss = 9999\n","  min_val_loss = 9999\n","  min_val_loss_snr = 9999\n","  max_train_loss_snr = -9999\n","\n","  for epoch in range(params['num_epochs']):\n","    print('Epoch {}/{}'.format(epoch, params['num_epochs']))\n","    print('-' * 10)\n","\n","    # Each epoch has a training and validation phase\n","    phases = ['train', 'val']\n","    for phase in phases:\n","      running_loss = 0.0\n","      running_loss_snr = 0.0\n","      if phase == 'train':\n","        model.train()\n","      else:\n","        model.eval()  # Set model to evaluate mode\n","\n","      # Iterate over data.\n","      for inputs in dataloaders[phase]:\n","        next_frames = inputs['next_frame'].to(device)\n","        targets = inputs['next_ppg_value'].to(device) \n","        # targets_hr = inputs['hr'].to(device)  \n","        next_frames = torch.transpose(next_frames, 1, 2)\n","        # print(next_frames.shape)\n","       \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward\n","        outputs = model(next_frames).squeeze()\n","        loss = criterion(outputs, targets)\n","        # print(loss.shape)\n","        if phase == 'train':\n","          loss.backward()\n","          # nn.utils.clip_grad_norm_(model.parameters(),1e3)\n","          optimizer.step()\n","\n","        # statistics\n","        running_loss += loss.item()\n","\n","      epoch_loss = running_loss / len(dataloaders[phase])\n","      print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n","\n","      if phase == 'val':\n","        val_loss_history.append(epoch_loss)\n","\n","        if epoch_loss < min_val_loss:\n","          print('saving in epoch', epoch)\n","          min_val_loss = epoch_loss\n","          print(f'new min loss: {min_val_loss}')\n","          torch.save(model.state_dict(), f\"checkpoints/{params['check_point_dir']}/model_best.pt\")\n","    \n","    # Scheduler\n","    scheduler.step()\n","    print('\\n')      \n","\n","    # Save\n","    torch.save(model.state_dict(), f\"checkpoints/{params['check_point_dir']}/model_ep{epoch}.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJr4K5S2aRH2"},"source":["**Tain test split**"]},{"cell_type":"code","metadata":{"id":"R8MdgH6KSji2"},"source":["fp_df = pd.read_excel($Path of label$)\n","print(len(fp_df))\n","fp_df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hm9FYV5oVzYx"},"source":["fp_df = fp_df.dropna(subset = ['Study ID','Fitzpatrick Skin Type'])\n","print(len(fp_df))\n","exception_subjects  = [31, 99] #this will drop the entire subject altogether.  \n","fp_df = fp_df[~fp_df['Study ID'].isin(exception_subjects)]\n","print(len(fp_df))\n","fp_df = fp_df.drop(columns=list(set(fp_df) - set(['Study ID', 'Fitzpatrick Skin Type'])))\n","fp_df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNEquL_lUcMy"},"source":["train_subject, test_subject = train_test_split(fp_df, test_size = 0.5, random_state = rseed, stratify = fp_df['Fitzpatrick Skin Type'] )# 50% subjects in train, 50% in val + test\n","validation_subject, test_subject = train_test_split(test_subject, test_size = 0.8, random_state = rseed, stratify = test_subject['Fitzpatrick Skin Type'] )# 10 out of 50 in val, remaining in test\n","# we need to repeat above split 5 times and retrain. \n","print(train_subject['Fitzpatrick Skin Type'].value_counts())\n","print(validation_subject['Fitzpatrick Skin Type'].value_counts())\n","print(test_subject['Fitzpatrick Skin Type'].value_counts())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oTyftdeDec1P"},"source":["train_subject['Study ID']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwMSWnryXR_K"},"source":["train_videos = []\n","validation_videos = []\n","train_videos = []\n","test_videos = []\n","for subject in train_subject['Study ID']:\n","  for j in range(1,6):\n","    train_videos.append(str(int(subject)) + '_' + str(j) )\n","for subject in test_subject['Study ID']:\n","  for j in range(1,6):\n","    test_videos.append(str(int(subject)) + '_' +str(j) )\n","for subject in validation_subject['Study ID']:\n","  for j in range(1,6):\n","    validation_videos.append(str(int(subject)) + '_' +str(j) )\n","\n","excepetion_videos = ['4_1','8_3', '10_5','16_5','49_5','34_1','58_5',] \n","train_videos = [ tv for tv in train_videos if tv not in excepetion_videos]\n","validation_videos = [ tv for tv in validation_videos if tv not in excepetion_videos]\n","test_videos = [ tv for tv in test_videos if tv not in excepetion_videos]\n","print(len(train_videos),train_videos)\n","print(len(validation_videos), validation_videos)\n","print(len(test_videos),test_videos)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UM3G9lOY5ieo"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"HYdNIto1eDzX"},"source":["params = {\n","  'lr': 0.0003,\n","  'min_lr_ratio': 0.01,\n","  'weight_decay': 0.01,\n","  'num_samples': 160,\n","  'seq_length': 256,\n","  'batch_size': 4,\n","  'img_shape': (80, 80),\n","  'num_epochs': 60,\n","  'snr_epoch': 10,\n","  'check_point_dir': '1440finetune_real_prn_v2',\n","  'pretrained_weights': None\n","}\n","\n","# create output dir\n","if params['check_point_dir']:\n","  try:\n","    os.makedirs(f\"checkpoints/{params['check_point_dir']}\")\n","    print(\"Output directory is created\")\n","  except FileExistsError:\n","    reply = input('Override existing weights? [y/n]')\n","    if reply == 'n':\n","      print('Add another outout path then!')\n","      sys.exit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhXGw6Kgenk4"},"source":["root_dir = [$Path of real data$, $Path of syn data]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SrcWIBkGo1K"},"source":["train_session_nums = train_videos\n","val_session_nums = validation_videos\n","\n","train_all = [] \n","val_all = []\n","train_session_names = []\n","val_session_names = []\n","\n","for cur_session_num in train_session_nums:\n","  sn = cur_session_num.split('_')[0]\n","  cur_session_name = 'subject'+ sn + '/' + cur_session_num\n","  train_session_names.append(cur_session_name)\n","print(train_session_names)\n","train_all.append(train_session_names)\n","\n","for cur_session_num in val_session_nums:\n","  sn = cur_session_num.split('_')[0]\n","  cur_session_name = 'subject'+ sn + '/' + cur_session_num\n","  val_session_names.append(cur_session_name)\n","print(val_session_names)\n","val_all.append(val_session_names)\n","\n","len_synthetic = 480\n","print(len_synthetic)\n","session_nums = np.random.permutation(np.arange(len_synthetic))\n","\n","train_session_syn_nums = []\n","val_session_syn_nums = []\n","train_session_syn_nums.append(session_nums[:np.int(len_synthetic*0.8)])\n","val_session_syn_nums.append(session_nums[np.int(len_synthetic*0.8):])\n","\n","train_all.append(list(train_session_syn_nums[0]))\n","val_all.append(list(val_session_syn_nums[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLdvleqaRF1B"},"source":["train_set = DatasetUBFC(\n","    root_dir=root_dir, \n","    session_names=train_all, \n","    num_samples=params['num_samples'],\n","    seq_length=params['seq_length'], \n","    resize_shape=params['img_shape']\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2xeNSBsiXlp"},"source":["val_set = DatasetUBFC(\n","    root_dir=root_dir, \n","    session_names=val_all, \n","    num_samples=params['num_samples'],\n","    seq_length=params['seq_length'], \n","    resize_shape=params['img_shape'],\n","    val = True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Da6MT7SyF4rO"},"source":["\n","ppg_train_loader = DataLoader(\n","    train_set,\n","    batch_size=params['batch_size'],\n","    shuffle=True,\n","    num_workers=0,\n","    pin_memory=True\n","    )\n","\n","\n","ppg_val_loader = DataLoader(\n","    val_set,\n","    batch_size=params['batch_size'],\n","    shuffle=False,\n","    num_workers=0,\n","    pin_memory=True\n","    )\n","\n","dataloaders = {'train': ppg_train_loader, 'val': ppg_val_loader}\n","print('\\nDataLoaders succesfully constructed!')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JjSVztz1wVju"},"source":["model = RPPGNetResnet(params['seq_length'])\n","\n","\n","# Device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device:', device)\n","\n","# If there are pretrained weights, initialize model\n","if params['pretrained_weights']:\n","  model.load_state_dict(tr.load(params['pretrained_weights']))\n","  print('\\nPre-trained weights are loaded!')\n","\n","# Copy model to working device\n","model = model.to(device)\n","\n","# criterion\n","criterion = Neg_Pearson()   # rPPG singal \n","\n","print('====loss====', criterion)\n","print('====lr====',  params['lr'])\n","print('====weight_decay====',  params['weight_decay'])\n","\n","optimizer = optim.AdamW(\n","    model.parameters(), \n","    lr=params['lr'], \n","    betas=(0.5, 0.999), \n","    weight_decay=params['weight_decay']\n","    )\n","\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(\n","    optimizer, T_max=params['num_epochs'], \n","    eta_min=params['min_lr_ratio'] * params['lr'], verbose=True\n","    )\n","\n","train_model(\n","    model, \n","    dataloaders, \n","    criterion, \n","    optimizer, \n","    scheduler, \n","    params\n","    )\n","\n","print('\\nTraining is finished without flaw!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTGHVxz9m8C1"},"source":[""],"execution_count":null,"outputs":[]}]}